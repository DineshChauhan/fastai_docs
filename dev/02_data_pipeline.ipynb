{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms and Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating *partially reversible functions*, which we call `Transform`s. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already.)\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. The following functionality is provided:\n",
    "\n",
    "- A `Transform` is created with an `encodes` and potentially `decodes` function. \n",
    "- `Pipeline` is a transform which composes transforms\n",
    "- `TfmdList` takes a collection and a transform, and provides an indexer (`__getitem__`) which dynamically applies the transform to the collection items.\n",
    "- `Tuplify` is a special `Trannsform` that takes a list of list of transforms or a list of `Pipeline`s, then aapplies them to the element it receives to return a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = getattr(t, name, noop)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "t = get_func(torch, 'zeros', dtype=torch.int64)(5)\n",
    "test_eq(t.dtype, torch.int64)\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title(o, ax=None, ctx=None):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    else: ax.set_title(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: show_title(\"title\"), \"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforms, are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done directly with the `multimethod` module and type-annotation in `Transofrm`, but you can also use the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return L(t).mapped(self._get) if is_listy(t) else self._get(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)\n",
    "test_eq(Func('sqrt')(torch), torch.sqrt)\n",
    "\n",
    "@patch\n",
    "def powx(x:math, a): return math.pow(x,a)\n",
    "@patch\n",
    "def powx(x:torch, a): return torch.pow(x,a)\n",
    "tst = Func('powx',a=2)([math, torch])\n",
    "test_eq([f.func for f in tst], [math.powx, torch.powx])\n",
    "for t in tst: test_eq(t.keywords, {'a': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Sig</code>\" class=\"doc_header\"><code>Sig</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Sig</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)\n",
    "test_eq(f(torch), torch.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SelfFunc():\n",
    "    \"Search for `name` attribute and call it with `args` and `kwargs` on any object it's passed.\"\n",
    "    def __init__(self, nm, *args, **kwargs): self.nm,self.args,self.kwargs = nm,args,kwargs\n",
    "    def __repr__(self): return f'self: {self.nm}({self.args}, {self.kwargs})'\n",
    "    def __call__(self, o):\n",
    "        if not is_listy(o): return getattr(o,self.nm)(*self.args, **self.kwargs)\n",
    "        else: return [getattr(o_,self.nm)(*self.args, **self.kwargs) for o_ in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between `Func` and `SelfFunc` is that `Func` will generate a function when you call it on a type. On the other hand, `SelfFunc` is already a function and each time you call it on an object it looks for the `name` attribute and call it on `args` and `kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = SelfFunc('sqrt')\n",
    "x = torch.tensor([4.])\n",
    "test_eq(tst(x), torch.tensor([2.]))\n",
    "assert isinstance(tst(x), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _SelfFunc():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return SelfFunc(k, *args, **kwargs)\n",
    "        return _inner\n",
    "    \n",
    "Self = _SelfFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Self</code>\" class=\"doc_header\"><code>Self</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Self</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Self, name=\"Self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Self` is just syntax sugar to create a `SelfFunc` object more easily with the syntax `Self.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Self.sqrt()\n",
    "x = torch.tensor([4.])\n",
    "test_eq(f(x), torch.tensor([2.]))\n",
    "assert isinstance(f(x), Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def positional_annotations(f):\n",
    "    \"Get list of annotated types for all positional params, or None if no annotation\"\n",
    "    sig = inspect.signature(f)\n",
    "    return [p.annotation if p.annotation != inspect._empty else None \n",
    "            for p in sig.parameters.values() if p.default == inspect._empty and p.kind != inspect._VAR_KEYWORD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, y:float): return x+y\n",
    "def f2(a, b=2): return a\n",
    "def f3(a:int, b:float=2): return a\n",
    "test_eq(positional_annotations(f1), [None, float])\n",
    "test_eq(positional_annotations(f2), [None])\n",
    "test_eq(positional_annotations(f3), [int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from multimethod import multimeta,DispatchError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Transform(metaclass=multimeta):\n",
    "    \"A function that `encodes` if `filt` matches, and optionally `decodes`\"\n",
    "    order,add_before_setup,filt,t = 0,False,None,None\n",
    "    def __init__(self,encodes=None,decodes=None):\n",
    "        self.encodes = getattr(self, 'encodes', noop) if encodes is None else encodes \n",
    "        self.decodes = getattr(self, 'decodes', noop) if decodes is None else decodes\n",
    "    \n",
    "    def _apply(self, fs, x, filt):\n",
    "        if self.filt is not None and self.filt!=filt: return x\n",
    "        if self.t: \n",
    "            gs = self._get_func(fs, self.t)\n",
    "            if is_listy(self.t) and len(positional_annotations(gs)) != len(self.t):\n",
    "                gs = [self._get_func(fs,t_) for t_ in self.t]\n",
    "                if len(gs) == 1: gs = gs[0]\n",
    "        else: gs=fs\n",
    "        if is_listy(gs): return tuple(f(x_) for f,x_ in zip(gs,x))\n",
    "        return gs(*L(x))\n",
    "\n",
    "    def _get_func(self,f,t):\n",
    "        idx = (object,) + tuple(t) if is_listy(t) else (object,t)\n",
    "        try: f = f.__func__[idx]\n",
    "        except DispatchError: return noop\n",
    "        return partial(f,self)\n",
    "    \n",
    "    def accept_types(self, t): self.t = t\n",
    "        # We can't create encodes/decodes here since patching might change things later\n",
    "        # So we call _get_func in _apply instead\n",
    "\n",
    "    def __call__(self, x, filt=None): return self._apply(self.encodes, x, filt)\n",
    "    def decode  (self, x, filt=None): return self._apply(self.decodes, x, filt)\n",
    "    def __getitem__(self, x): return self(x) # So it can be used as a `Dataset`\n",
    "\n",
    "add_docs(Transform,\n",
    "         __call__=\"Dispatch and apply the proper encodes to `x` if `filt` matches\",\n",
    "         decode=\"Dispatch and apply the proper decodes to `x` if `filt` matches\",\n",
    "         accept_types=\"Indicate the type of input received by the transform is `t`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a transformation pipeline some steps need to be reversible - for instance, if you turn a string (such as *dog*) into an int (such as *1*) for modeling, then for display purposes you'll want to turn it back to a string again (e.g. when you have a prediction). In addition, you may wish to only run the transformation for a particular data subset, such as the training set.\n",
    "\n",
    "`Transform` provides all this functionality. `filt` is some dataset index (e.g. provided by `DataSource`), and you provide `encodes` and optional `decodes` functions for your code. You can pass `encodes` and `decodes` functions directly to the constructor for quickly creating simple transforms. You can also create several `encodes` or `decodes` methods for different types of objects with proper type annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Transform(operator.neg, decodes=operator.neg)\n",
    "start = 4\n",
    "t = tfm(start)\n",
    "test_eq(t, -4)\n",
    "test_eq(t, tfm[start]) #You can use a transform as a dataset\n",
    "test_eq(tfm.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddOne(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "test_eq(addt(start,filt=1), 5)\n",
    "test_eq(addt(start,filt=0), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.__call__</code>\" class=\"doc_header\"><code>Transform.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.__call__</code>(**`x`**, **`filt`**=*`None`*)\n",
       "\n",
       "Dispatch and apply the proper encodes to `x` if `filt` matches"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.decode</code>\" class=\"doc_header\"><code>Transform.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.decode</code>(**`x`**, **`filt`**=*`None`*)\n",
       "\n",
       "Dispatch and apply the proper decodes to `x` if `filt` matches"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.accept_types</code>\" class=\"doc_header\"><code>Transform.accept_types</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.accept_types</code>(**`t`**)\n",
       "\n",
       "Indicate the type of input received by the transform is `t`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.accept_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point in the data-collection pipeline, your objects will be tuples (usually input,label). There are then different behaviors you might want your `Transform` to adopt such as:\n",
    "- being applied to the tuple and returning a new tuple\n",
    "- being applied to each part of the tuple\n",
    "- being applied to some parts of the tuple but not all\n",
    "\n",
    "You can control which behavior will be used with the signature of your `encodes` function. If it accepts several arguments (without defaults), then the transform will be applied on the tuple and expected to return a tuple. If your `encodes` function only accepts one argument, it will be applied on every part of the tuple. You can even control which part of the tuples with a type annotation: the tranform will only be applied to the items in the tuple that correspond to that type.\n",
    "\n",
    "All of this is enabled the method `accept_types` that is called in the setup of a `Pipeline` (so out of the blue your transform object won't have this behavior). The `Pipeline` will analyze the type of objects (as given by the return annotation of any transform) and pass them along, wich tells the transform it will receive a given type (or a tuple of given types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on the tuple as a whole\n",
    "class _Add(Transform):\n",
    "    def encodes(self, x, y): return (x+y,y)\n",
    "    def decodes(self, x, y): return (x-y,y)\n",
    "\n",
    "addt = _Add()\n",
    "addt.accept_types([float,float])\n",
    "t = addt([1,2])\n",
    "test_eq(t, (3,2))\n",
    "test_eq(addt.decode(t), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on all part of the tuple\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "addt.accept_types([float,float])\n",
    "t = addt([1,2])\n",
    "test_eq(t, (2,3))\n",
    "test_eq(addt.decode(t), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on all integers of the tuple\n",
    "#Also note that your tuples can have more than two elements\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x:numbers.Integral): return x+1\n",
    "    def encodes(self, x:float): return x*2\n",
    "    def decodes(self, x:numbers.Integral): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "addt.accept_types([float, int, float])\n",
    "start = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(cls):\n",
    "    \"Decorator for registering a new `encodes` or `decodes` function in a tranform `cls`\"\n",
    "    def _inner(f):\n",
    "        if   f.__name__=='encodes': cls.encodes.register(f)\n",
    "        elif f.__name__=='decodes': cls.decodes.register(f)\n",
    "        else: raise Exception('Function must be \"encodes\" or \"decodes\"')\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform(_AddOne)\n",
    "def decodes(self, x:float): return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = addt(start)\n",
    "test_eq(t, (2,3,6))\n",
    "test_eq(addt.decode(t), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compose_tfms(x, tfms, func_nm='__call__', reverse=False, **kwargs):\n",
    "    \"Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order\"\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    for tfm in tfms: x = getattr(tfm,func_nm,noop)(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddOne(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "    \n",
    "tfms = [_AddOne(), Transform(torch.sqrt)]\n",
    "t = compose_tfms(tensor([3.]), tfms)\n",
    "test_eq(t, tensor([2.]))\n",
    "test_eq(compose_tfms(t, tfms, 'decodes'), tensor([1.]))\n",
    "test_eq(compose_tfms(tensor([4.]), tfms, reverse=True), tensor([3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_ret(func):\n",
    "    \"Get the return annotation of `func`\"\n",
    "    ann = getattr(func,'__annotations__', None)\n",
    "    if not ann: return None\n",
    "    typ = ann.get('return')\n",
    "    return list(typ.__args__) if getattr(typ, '_name', '')=='Tuple' else typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def f1(x) -> float: return x\n",
    "test_eq(_get_ret(f1), float)\n",
    "def f2(x) -> Tuple[float,float]: return x\n",
    "test_eq(_get_ret(f2), [float,float])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TupleOfTypes():\n",
    "    \"Class that handles the show method of a tuple of types\"\n",
    "    def __init__(self, ts): self.ts = ts\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for p,t in zip(o,self.ts): ctx = t.show(p, ctx=ctx, **kwargs)\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class String():\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): return show_title(str(o), ctx=ctx)\n",
    "\n",
    "class String2():\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): return show_title(\"String: \"+str(o), ctx=ctx)\n",
    "    \n",
    "t = TupleOfTypes([String,String2])\n",
    "test_stdout(lambda: t.show(['test', 'test']), 'test\\nString: test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def can_show(t):\n",
    "    \"Check if `t` can show itself and wrap tuples in `TupleOfTypes`\"\n",
    "    if is_listy(t):\n",
    "        res = [can_show(t_) for t_ in t]\n",
    "        return TupleOfTypes(res) if len([o for o in res if o is None]) == 0 else None\n",
    "    return t if hasattr(t, 'show') else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: A list of types is considered to be able to show itself when all the types in it have a show method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline():\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup with types\"\n",
    "    def __init__(self, funcs=None, t=None): \n",
    "        if isinstance(funcs, Pipeline): funcs = funcs.raws\n",
    "        self.raws,self.fs,self.t_show = L(funcs),[],None\n",
    "        if len(self.raws) == 0: self.final_t = t\n",
    "        else:\n",
    "            for i,f in enumerate(self.raws.sorted(key='order')):\n",
    "                if not isinstance(f,Transform): f = Transform(f)\n",
    "                f.accept_types(t)\n",
    "                self.fs.append(f)\n",
    "                if self.t_show is None: self.t_idx,self.t_show = i,can_show(t)\n",
    "                t = _get_ret(f.encodes) or t\n",
    "            if self.t_show is None: self.t_idx,self.t_show = i+1,can_show(t)\n",
    "            self.final_t = t\n",
    "    \n",
    "    def new(self, t=None): return Pipeline(self, t)\n",
    "    def __repr__(self): return f\"Pipeline over {self.fs}\"\n",
    "    \n",
    "    def setup(self, items=None):\n",
    "        tfms,self.fs = self.fs,[]\n",
    "        for t in tfms:\n",
    "            if t.add_before_setup:     self.fs.append(t)\n",
    "            if hasattr(t, 'setup'):    t.setup(items)\n",
    "            if not t.add_before_setup: self.fs.append(t)\n",
    "                \n",
    "    def __call__(self, o, **kwargs): return compose_tfms(o, self.fs)\n",
    "    def decode  (self, i, **kwargs): return compose_tfms(i, self.fs, func_nm='decode', reverse=True)\n",
    "    #def __getitem__(self, x): return self(x)\n",
    "    #def decode_at(self, idx): return self.decode(self[idx])\n",
    "    #def show_at(self, idx):   return self.show(self[idx])\n",
    "    \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        if self.t_show is None: return self.decode(o)\n",
    "        o = compose_tfms(o, self.fs[self.t_idx:], func_nm='decode', reverse=True)\n",
    "        return self.t_show.show(o, ctx=ctx, **kwargs)\n",
    "\n",
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `tfms` on `o`\",\n",
    "         decode=\"Compose `decode` of all `tfms` on `i`\",\n",
    "         new=\"Create a new `Pipeline`with the same `tfms` and a new initial `t`\",\n",
    "         show=\"Show item `o`\",\n",
    "         setup=\"Go through the transforms in order and call their potential setup on `items`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of transforms are often applied in a particular order, and decoded by applying in the reverse order. `Pipeline` provides this functionality, and also ensures during its initialization that each transform get the proper functions according to the type of the previous transform. If any transform provides a type with a return annotation, this type is passed along to the next tranforms (until being overwritten by a new return annotation). Such a type can be useful when transforms filter depending on a given type (usually for data augmentation) or to provide a show method.\n",
    "\n",
    "Here's some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipeline is noop\n",
    "pipe = Pipeline()\n",
    "test_eq(pipe(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a standard pipeline\n",
    "class floatTfm(Transform):\n",
    "    def encodes(self, x): return float(x)\n",
    "    def decodes(self, x): return int(x)\n",
    "\n",
    "float_tfm=floatTfm()\n",
    "def neg(x) -> String: return -x\n",
    "neg_tfm = Transform(neg, neg)\n",
    "    \n",
    "pipe = Pipeline([neg_tfm, float_tfm])\n",
    "\n",
    "start = 2\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "#test_eq(t, pipe[2])\n",
    "test_eq(pipe.decode(t), start)\n",
    "#show decodes up to the point of the first transform that introduced the type that shows, not included\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([float_tfm,neg_tfm])\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "# `show` comes from String on the last transform so nothing is decoded\n",
    "test_stdout(lambda:pipe.show(t), '-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check show method on tuples\n",
    "def dbl_neg(x) -> Tuple[String,String2]: return (-x, -x)\n",
    "pipe = Pipeline(dbl_neg)\n",
    "t = pipe(2)\n",
    "test_stdout(lambda: pipe.show(t), '-2\\nString: -2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.__call__</code>\" class=\"doc_header\"><code>Pipeline.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.__call__</code>(**`o`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `__call__` of all `tfms` on `o`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode</code>\" class=\"doc_header\"><code>Pipeline.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode</code>(**`i`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `decode` of all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.new</code>\" class=\"doc_header\"><code>Pipeline.new</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.new</code>(**`t`**=*`None`*)\n",
       "\n",
       "Create a new [`Pipeline`](/data.pipeline.v2.html#Pipeline)with the same `tfms` and a new initial `t`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.setup</code>\" class=\"doc_header\"><code>Pipeline.setup</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline_v2.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.setup</code>(**`items`**=*`None`*)\n",
       "\n",
       "Go through the transforms in order and call their potential setup on `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the setup, the `Pipeline` starts with no transform and adds them one at a time, so that during its setup, each transfrom get the items processed up to its point and not after. Depending on the attribute `add_before_setup`, the transform is added after the setup (default behaivor) so it's not called on the items used for the setup, or before (in which case it's called on the values used for setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test is below with TfmdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmedList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdList(GetAttr):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of `items`\"\n",
    "    _xtra = 'decode __call__ show'.split()\n",
    "    \n",
    "    def __init__(self, items, tfms, do_setup=True):\n",
    "        self.items = L(items)\n",
    "        self.default = self.tfms = Pipeline(tfms)\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"Transformed item(s) at `i`\"\n",
    "        its = self.items[i]\n",
    "        return its.mapped(self.tfms) if is_iter(i) else self.tfms(its)\n",
    "    \n",
    "    def decode_batch(self, b, **kwargs):\n",
    "        \"Decode `b`, a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\"\n",
    "        transp = L(zip(*L(b)))\n",
    "        return transp.mapped(self.decode, **kwargs).zipped()\n",
    "\n",
    "    def setup(self): self.tfms.setup(self)\n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.tfms, do_setup=False)\n",
    "    def decode_at(self, idx, filt=None): return self.decode(self[idx], filt=filt)\n",
    "    def show_at(self, idx): return self.show(self[idx])\n",
    "    def __eq__(self, b): return all_equal(self, b)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms}\"\n",
    "    \n",
    "    _docs = dict(setup=\"Transform setup with self\",\n",
    "                 decode_at=\"Decoded item at `idx`\",\n",
    "                 decode_batch=\"Decode the items in `b\",\n",
    "                 show_at=\"Show item at `idx`\",\n",
    "                 subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` can either be a `Pipeline` or a list of transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#3) [1,2,3]\n",
       "tfms - Pipeline over [<__main__.Transform object at 0x7f03b8858208>, <__main__.floatTfm object at 0x7f03b88580b8>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = TfmdList([1,2,3], [neg_tfm, float_tfm])\n",
    "t = tl[1]\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq(tl.decode(t), 2)\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1.,-3.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#5) [dog_0.jpg,cat_0.jpg,cat_2.jpg,cat_1.jpg,dog_1.jpg]\n",
       "tfms - Pipeline over [<__main__.Transform object at 0x7f03b8861cc0>, <__main__._Cat object at 0x7f03b88619b0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def encodes(self, o): return self.o2i[o]\n",
    "    def decodes(self, o): return self.vocab[o]\n",
    "    def setup(self, items): self.vocab,self.o2i = uniqueify(items, sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o) -> String: return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq([1,0,0,0,1], tl)\n",
    "test_eq(1, tl[-1])\n",
    "test_eq([1,0], tl[0,1])\n",
    "t = list(tl)\n",
    "test_eq([1,0,0,0,1], t)\n",
    "test_eq(['dog','cat','cat','cat','dog'], map(tl.decode,t))\n",
    "test_stdout(lambda:tl.show_at(0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test of add_before_setup\n",
    "class _AddSome(Transform):\n",
    "    def __init__(self):   self.a = 2\n",
    "    def encodes(self, x): return x+self.a\n",
    "    def decodes(self, x): return x-self.a\n",
    "    def setup(self, items): self.a = tensor(items).float().mean().item()\n",
    "        \n",
    "tl1 = TfmdList([1,2,3,4], _AddSome())\n",
    "test_eq(tl1.tfms.fs[0].a, 2.5) #Setup on the raw items, mean is 2.5\n",
    "\n",
    "_AddSome.add_before_setup = True\n",
    "tl1 = TfmdList([1,2,3,4], _AddSome())\n",
    "test_eq(tl1.tfms.fs[0].a, 4.5) #Setup on the tfmed items, mean is 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.__getitem__</code>\" class=\"doc_header\"><code>TfmdList.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.__getitem__</code>(**`i`**)\n",
       "\n",
       "Transformed item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.decode_at</code>\" class=\"doc_header\"><code>TfmdList.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.decode_at</code>(**`idx`**, **`filt`**=*`None`*)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),tl.decode(tl[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.decode_batch</code>\" class=\"doc_header\"><code>TfmdList.decode_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.decode_batch</code>(**`b`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Decode the items in `b"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.decode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: tl.show_at(1), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.subset</code>\" class=\"doc_header\"><code>TfmdList.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.subset</code>(**`idxs`**)\n",
       "\n",
       "New [`TfmdList`](/data.pipeline.html#TfmdList) that only includes items at `idxs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuplify -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _fake_annote(t):\n",
    "    def _inner(x): return x\n",
    "    if is_listy(t):\n",
    "        new_t = Tuple[int]\n",
    "        new_t.__args__ = tuple(t)\n",
    "        t = new_t\n",
    "    setattr(_inner, '__annotations__', {'return': t})\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tuplify(Transform):\n",
    "    \"Create tuple by applying each of of `tfms` to the passed `o`\"\n",
    "    add_before_setup=True\n",
    "    def __init__(self, tfms=None):\n",
    "        if tfms is None: tfms = [None]\n",
    "        self.activ,self.tfms = None,L(tfms).mapped(Pipeline)\n",
    "        self.encodes = _fake_annote([tfm.final_t for tfm in self.tfms])\n",
    "\n",
    "    def encodes(self, o):\n",
    "        return [t(o) for t in self.tfms] if self.activ is None else self.tfms[self.activ](o) \n",
    "    \n",
    "    def __call__(self, o, *args, **kwargs):\n",
    "        \"List of output of each of `tfms` on `o`\"\n",
    "        if self.activ is not None: return self.tfms[self.activ](o, *args, **kwargs)\n",
    "        return [t(o, *args, **kwargs) for t in self.tfms]\n",
    "\n",
    "    def decode(self, o, **kwargs): return [t.decode(p, **kwargs) for p,t in zip(o,self.tfms)]\n",
    "    def __repr__(self): return f'Tuplify({self.tfms})'\n",
    "\n",
    "    def setup(self, o=None):\n",
    "        \"Setup each of `tfms` independently\"\n",
    "        for i,tfm in enumerate(self.tfms):\n",
    "            self.activ = i\n",
    "            tfm.setup(o)\n",
    "        self.activ=None\n",
    "    \n",
    "    @classmethod\n",
    "    def piped(cls, tfms=None, tuple_tfms=None):\n",
    "        \"Return a `Pipeline` that combines `Tuplify` over `tfms`, optionally followed by any `tuple_tfms`\"\n",
    "        return Pipeline(cls(tfms) + L(tuple_tfms))\n",
    "        \n",
    "    xt,yt = add_props(lambda i,x:x.tfms[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` is a list of objects that can be:\n",
    "- one transform\n",
    "- a list of transforms\n",
    "- a `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TNorm(Transform):\n",
    "    #def __init__(self): self.m,self.s = 0,1\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setup(self, items):\n",
    "        its = tensor(items).float()\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tl = TfmdList(items, Tuplify.piped([neg_tfm, [neg_tfm,_TNorm()]]))\n",
    "x,y = zip(*tl)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, [-1,-2,-3,-4])\n",
    "test_stdout(lambda:tl.show_at(1), '-2\\ntensor(0.3873)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1, -2, -3, -4),\n",
       " (tensor(1.1619), tensor(0.3873), tensor(-0.3873), tensor(-1.1619))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = list(zip(*tl))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b  [(-1, -2, -3, -4), (tensor(1.1619), tensor(0.3873), tensor(-0.3873), tensor(-1.1619))]\n",
      "bd (#2) [(#4) [1,2,3,4],(#4) [tensor(1.),tensor(2.),tensor(3.),tensor(4.)]]\n"
     ]
    }
   ],
   "source": [
    "# Create a \"batch\"\n",
    "b = list(zip(*tl))\n",
    "bd = tl.decode_batch(b)\n",
    "\n",
    "test_eq(len(bd),2)\n",
    "test_eq(bd[0],items)\n",
    "test_eq(bd[1],items)\n",
    "test_eq(type(bd[1][0]),Tensor)\n",
    "print('b ',b)\n",
    "print('bd',bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty tuplify\n",
    "tp = Tuplify()\n",
    "tp.setup()\n",
    "test_eq(tp(1), [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Tuplify.piped</code>\" class=\"doc_header\"><code>Tuplify.piped</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Tuplify.piped</code>(**`tfms`**=*`None`*, **`tuple_tfms`**=*`None`*)\n",
       "\n",
       "Return a [`Pipeline`](/data.pipeline.v2.html#Pipeline) that combines `Tuplify` over `tfms`, optionally followed by any `tuple_tfms`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Tuplify.piped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 02_data_pipeline_v2-multi.ipynb.\n",
      "Converted 02_data_pipeline_v2.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-meta.ipynb.\n",
      "Converted 07_pets_tutorial-oo.ipynb.\n",
      "Converted 07_pets_tutorial-oo1.ipynb.\n",
      "Converted 07_pets_tutorial-oo2-meta.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_augmentation.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
